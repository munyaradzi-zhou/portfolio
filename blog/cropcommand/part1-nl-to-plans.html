<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>From Natural Language to Robot Task Plans — CropCommand Blog — Munyaradzi Comfort Zhou</title>
  <link rel="stylesheet" href="../../css/variables.css">
  <link rel="stylesheet" href="../../css/main.css">
</head>
<body>
  <nav class="nav">
    <div class="nav-inner">
      <a href="../../index.html" class="nav-brand">MCZ</a>
      <button class="nav-toggle" aria-label="Toggle navigation">
        <span></span><span></span><span></span>
      </button>
      <ul class="nav-links">
        <li><a href="../../index.html">Home</a></li>
        <li><a href="../../projects.html">Projects</a></li>
        <li><a href="../../blogs.html">Blog</a></li>
        <li><a href="../../cv.html">CV</a></li>
      </ul>
    </div>
  </nav>
  <main class="container">
    <article>
      <div class="post-header">
        <h1>From Natural Language to Robot Task Plans</h1>
        <p class="meta">CropCommand Series · Part 1 of 3</p>
      </div>
      <div class="post-content">

        <p>Imagine standing at the edge of a five-hectare wheat field, a storm front visible on the horizon, and telling your fleet of agricultural robots: <em>"Spray the northern tomato field before the rain, avoiding the organic section."</em> That single sentence encodes an action (spray), a target (northern tomato field), a temporal constraint (before the rain), and a spatial restriction (avoid the organic section). For a human farm manager the meaning is obvious. For a robot, it is an unsolved problem that sits at the intersection of natural language understanding, task planning, and constraint satisfaction.</p>

        <p>CropCommand is a system I built to bridge that gap. It takes free-form natural language commands from a farmer, parses them into structured intents, decomposes those intents into ordered sequences of atomic robot actions, and then validates the resulting plan against real-world constraints before presenting it back for human approval. This post &mdash; the first in a three-part series &mdash; walks through the front half of that pipeline: parsing, entity extraction, and task decomposition.</p>

        <h2>Why Natural Language Matters for Agricultural Robotics</h2>

        <p>Modern precision agriculture already deploys autonomous platforms &mdash; ground sprayers, drone surveyors, robotic harvesters. But programming these machines still requires either vendor-specific GUIs, waypoint editors, or scripting languages. The farmer's mental model of "spray the north field before it rains" has to be manually translated into coordinates, chemical rates, nozzle settings, and timing windows.</p>

        <p>That translation step is the bottleneck. It demands technical expertise that many farm operators do not have, and it is slow enough that time-sensitive decisions &mdash; like getting a fungicide application in before precipitation &mdash; can be missed entirely.</p>

        <p>CropCommand removes that bottleneck by accepting instructions in the language farmers already use.</p>

        <h2>The Intent Parser: From Words to Structure</h2>

        <p>The entry point for every command is the <code>IntentParser</code> class, defined in <code>cropcommand.nlp.intent_parser</code>. Its job is to take a raw string and produce a <code>ParsedCommand</code> &mdash; a Pydantic model that captures the structured meaning of the utterance.</p>

        <h3>Command Intents</h3>

        <p>The parser recognizes eight high-level intent categories, represented by the <code>CommandIntent</code> enum:</p>

<pre><code>class CommandIntent(str, Enum):
    SPRAY = "spray"
    HARVEST = "harvest"
    WEED = "weed"
    SURVEY = "survey"
    NAVIGATE = "navigate"
    SCHEDULE = "schedule"
    STATUS_CHECK = "status_check"
    CANCEL = "cancel"</code></pre>

        <p>These cover the core operations of a diversified farm: applying chemicals, collecting crops, removing weeds, aerial surveying, moving robots, scheduling future work, checking system status, and aborting active tasks.</p>

        <p>Intent detection uses a priority-ordered list of compiled regular expressions:</p>

<pre><code>_INTENT_PATTERNS: List[tuple[CommandIntent, re.Pattern[str]]] = [
    (CommandIntent.CANCEL,       re.compile(r"\b(cancel|abort|stop)\b", re.IGNORECASE)),
    (CommandIntent.STATUS_CHECK, re.compile(r"\b(status|check|report|where is)\b", re.IGNORECASE)),
    (CommandIntent.SPRAY,        re.compile(r"\b(spray|apply|fungicide|herbicide|...)\b", re.IGNORECASE)),
    (CommandIntent.HARVEST,      re.compile(r"\b(harvest|reap|collect|pick|gather)\b", re.IGNORECASE)),
    # ... and so on
]</code></pre>

        <p>The ordering is deliberate. Safety-critical intents like <code>CANCEL</code> are checked first, so that "cancel the spray operation" is correctly classified as a cancellation rather than a spray command. If no pattern matches, the parser falls back to <code>NAVIGATE</code> with a low confidence score of 0.40, signalling to downstream components that the interpretation is uncertain.</p>

        <h3>The ParsedCommand Model</h3>

        <p>The output of parsing is a <code>ParsedCommand</code> instance:</p>

<pre><code>class ParsedCommand(BaseModel):
    intent: CommandIntent
    target_field: Optional[str]
    robot_preference: Optional[str]
    temporal_constraint: Dict[str, Any]
    spatial_constraint: Dict[str, Any]
    parameters: Dict[str, Any]
    raw_command: str
    confidence: float</code></pre>

        <p>Every field has a clear role. <code>target_field</code> is the primary location the command references. <code>robot_preference</code> captures explicit robot mentions ("use the drone"). <code>temporal_constraint</code> and <code>spatial_constraint</code> hold structured dictionaries that the downstream planner and constraint engine will consume. <code>parameters</code> is a catch-all for action-specific details: chemical type, application rate, traversal pattern.</p>

        <p>The <code>confidence</code> score is a simple but important signal. When the parser is uncertain &mdash; say the command is ambiguous or uses vocabulary the patterns do not cover &mdash; that low confidence propagates through the pipeline and eventually surfaces to the user in the form of a request for clarification.</p>

        <h2>Entity Extraction: Mining the Details</h2>

        <p>Intent detection answers the question <em>"what does the user want to do?"</em> Entity extraction answers <em>"where, when, how, and with what?"</em> The <code>entity_extractor</code> module provides five focused extraction functions, each targeting a different entity class.</p>

        <h3>Field References</h3>

<pre><code>_FIELD_PATTERN = re.compile(
    r"\b(?:field\s+)?(north|south|east|west|organic|main|central|upper|lower)"
    r"(?:\s+field)?\b",
    re.IGNORECASE,
)</code></pre>

        <p>The <code>extract_field_references</code> function handles both natural phrasing ("the northern field") and identifier-style references ("field_01"). It normalizes results into a consistent title-case format like "Field North" &mdash; matching the field names used in the farm environment model.</p>

        <h3>Temporal Constraints</h3>

        <p>Temporal extraction is richer. The system recognizes three patterns:</p>

        <ul>
          <li><strong>Absolute deadlines:</strong> "before 3pm", "by 12:00"</li>
          <li><strong>Relative time references:</strong> "tomorrow", "in 2 hours", "this afternoon"</li>
          <li><strong>Time-of-day markers:</strong> "morning", "dawn", "sunset"</li>
        </ul>

        <p>These are extracted into a dictionary:</p>

<pre><code>{
    "deadline": "3pm",
    "deadline_type": "before_time",
    "time_of_day": "afternoon"
}</code></pre>

        <p>This structured representation lets the constraint engine reason about whether a plan can actually complete within the specified window.</p>

        <h3>Spatial Constraints</h3>

        <p>Spatial extraction targets two categories &mdash; zones to avoid and zones to focus on:</p>

<pre><code>_AVOID_PATTERN = re.compile(
    r"\b(?:avoid|skip|stay away from|exclude|...)\s+(?:the\s+)?([\w\s]+?)(?:\s+zone|...)\b",
    re.IGNORECASE,
)
_TARGET_ZONE_PATTERN = re.compile(
    r"\b(?:only|just|focus on|concentrate on|target)\s+(?:the\s+)?([\w\s]+?)(?:\s+zone|...)\b",
    re.IGNORECASE,
)</code></pre>

        <p>When the farmer says "avoiding the organic section," the avoid pattern fires and produces <code>{"avoid_zones": ["organic"]}</code>. This spatial restriction is passed through the entire pipeline and eventually enforced during route planning.</p>

        <h3>Crop and Robot References</h3>

        <p>The extractor also maintains a vocabulary of 30+ common crop types (wheat, corn, tomatoes, strawberries, etc.) and robot keywords (drone, sprayer, harvester, tractor). These are matched with simple word-boundary patterns and fed into the <code>parameters</code> and <code>robot_preference</code> fields of the <code>ParsedCommand</code>.</p>

        <h2>Task Decomposition: From Intent to Atomic Actions</h2>

        <p>Parsing tells us <em>what</em> to do. Decomposition tells us <em>how</em> &mdash; breaking a high-level intent into an ordered sequence of atomic <code>TaskAction</code> objects that a robot can execute one at a time.</p>

        <h3>The TaskAction Model</h3>

<pre><code>class TaskAction(BaseModel):
    id: int                           # Unique step ID (1-based)
    action_type: ActionType           # NAVIGATE, SPRAY, HARVEST, WEED, SURVEY, CONFIGURE, RETURN_BASE, WAIT
    target_field: Optional[str]       # Which field this step targets
    parameters: Dict[str, Any]        # Step-specific parameters
    estimated_duration_minutes: float  # Time estimate
    dependencies: List[int]           # IDs of prerequisite steps</code></pre>

        <p>The <code>dependencies</code> list is critical. It encodes the partial ordering between steps: step 4 (spray) cannot start until step 3 (navigate) is complete. This gives the scheduler flexibility to parallelize independent branches while respecting causal relationships.</p>

        <h3>Intent-Specific Decomposition</h3>

        <p>The <code>TaskDecomposer</code> uses a dispatch table to route each intent to a specialized decomposition function:</p>

<pre><code>_DECOMPOSITION_MAP = {
    CommandIntent.SPRAY:        _decompose_spray,
    CommandIntent.HARVEST:      _decompose_harvest,
    CommandIntent.WEED:         _decompose_weed,
    CommandIntent.SURVEY:       _decompose_survey,
    CommandIntent.NAVIGATE:     _decompose_navigate,
    CommandIntent.STATUS_CHECK: _decompose_status_check,
    CommandIntent.CANCEL:       _decompose_cancel,
}</code></pre>

        <p>Each function encodes domain knowledge about the standard operating procedure for that task type.</p>

        <h3>Spray Decomposition: A Closer Look</h3>

        <p>Spraying is the most complex decomposition, producing five sequential steps:</p>

        <ol>
          <li><strong>WAIT</strong> &mdash; Verify weather conditions are within safe limits for spraying (2 min)</li>
          <li><strong>CONFIGURE</strong> &mdash; Set up the robot: nozzle type, chemical, application rate, traversal pattern (3 min)</li>
          <li><strong>NAVIGATE</strong> &mdash; Travel from current location to the target field (5 min)</li>
          <li><strong>SPRAY</strong> &mdash; Execute the spraying pattern across the field (~15 min/hectare)</li>
          <li><strong>RETURN_BASE</strong> &mdash; Drive back to the base station (5 min)</li>
        </ol>

        <p>The duration estimates are parameterized by field area:</p>

<pre><code>area = _field_area(field_name, env)
spray_duration = max(10.0, area * 15.0)  # ~15 min per hectare</code></pre>

        <p>A 5-hectare field produces a spray step of 75 minutes; a 0.5-hectare plot is clamped to the 10-minute minimum. These estimates are rough but useful: they let the constraint engine check whether the plan fits within a deadline and they give the farmer a meaningful time estimate in the plan explanation.</p>

        <p>The CONFIGURE step automatically defaults to a boustrophedon (back-and-forth) traversal pattern if the user did not specify one &mdash; reflecting the standard practice for maximizing coverage efficiency in rectangular fields.</p>

        <h3>Weed Decomposition: Survey-Then-Act</h3>

        <p>The weeding pipeline adds an intermediate survey step:</p>

        <ol>
          <li><strong>NAVIGATE</strong> to the field</li>
          <li><strong>SURVEY</strong> for weed locations (mode: <code>weed_detection</code>)</li>
          <li><strong>WEED</strong> using mechanical removal</li>
          <li><strong>RETURN_BASE</strong></li>
        </ol>

        <p>This is a real pattern in precision agriculture. You survey first to build a weed map, then execute targeted removal rather than treating the entire field. CropCommand models this two-phase approach directly in the decomposition.</p>

        <h2>Walking Through the Example</h2>

        <p>Let us trace the complete example: <strong>"Spray the northern tomato field before the rain, avoiding the organic section."</strong></p>

        <h3>Step 1: Intent Detection</h3>

        <p>The word "spray" matches the <code>SPRAY</code> pattern. Confidence: 0.85.</p>

        <h3>Step 2: Entity Extraction</h3>

        <ul>
          <li><strong>Field references:</strong> "northern" matches the field pattern, producing <code>"Field North"</code>.</li>
          <li><strong>Crop references:</strong> "tomato" matches the crop vocabulary, added to <code>parameters["crops"]</code>.</li>
          <li><strong>Temporal constraints:</strong> "before the rain" &mdash; the word "before" triggers the deadline pattern. While "the rain" is not a clock time, the temporal extractor captures the relative time signal. The constraint engine will cross-reference this with the weather forecast.</li>
          <li><strong>Spatial constraints:</strong> "avoiding the organic section" triggers the avoid pattern, producing <code>{"avoid_zones": ["organic"]}</code>.</li>
        </ul>

        <h3>Step 3: The ParsedCommand</h3>

<pre><code>ParsedCommand(
    intent=CommandIntent.SPRAY,
    target_field="Field North",
    robot_preference=None,
    temporal_constraint={"relative_time": "before the rain"},
    spatial_constraint={"avoid_zones": ["organic"]},
    parameters={"crops": ["tomato"]},
    raw_command="Spray the northern tomato field before the rain, avoiding the organic section",
    confidence=0.85,
)</code></pre>

        <h3>Step 4: Task Decomposition</h3>

        <p>The <code>_decompose_spray</code> function generates five actions. The avoid zones from the spatial constraint are injected into each task's parameters by the <code>PlanGenerator</code>:</p>

<pre><code>avoid_zones = parsed.spatial_constraint.get("avoid_zones", [])
if avoid_zones:
    for task in tasks:
        task.parameters["avoid_zones"] = avoid_zones</code></pre>

        <p>This means every step in the plan is aware of the organic section restriction. The navigation planner will route around it; the spray execution will skip it; the return path will avoid it.</p>

        <h3>Step 5: The Execution Plan</h3>

        <p>The <code>PlanGenerator</code> wraps the tasks into an <code>ExecutionPlan</code> with a unique ID, a confidence score, and a human-readable explanation:</p>

<pre><code>Intent: spray. Target field: Field North.
Plan consists of 5 actions.
Temporal constraints: {'relative_time': 'before the rain'}.
Spatial constraints: {'avoid_zones': ['organic']}.</code></pre>

        <p>This plan is not yet validated. It still needs to pass through the constraint engine (Part 2) and the human feedback loop (Part 3) before execution.</p>

        <h2>Design Decisions and Trade-offs</h2>

        <p><strong>Why rule-based parsing instead of an LLM?</strong> Determinism and latency. In a safety-critical agricultural context, you need to know exactly how a command will be interpreted. Regex patterns are fast, predictable, and auditable. They can be extended by adding new patterns without retraining a model. The trade-off is coverage: unusual phrasings may not match. The low-confidence fallback mechanism mitigates this by flagging uncertain interpretations for human review.</p>

        <p><strong>Why Pydantic models?</strong> Validation at the boundary. Every <code>ParsedCommand</code>, <code>TaskAction</code>, and <code>ExecutionPlan</code> is a Pydantic <code>BaseModel</code> with type annotations, default values, and constraints (e.g., <code>confidence</code> is clamped to [0, 1]). This means malformed data is caught immediately rather than propagating through the pipeline and causing cryptic failures downstream.</p>

        <p><strong>Why a dispatch table for decomposition?</strong> Extensibility. Adding a new task type (say, <code>SEED</code> for planting operations) requires three changes: a new <code>CommandIntent</code> variant, a new <code>_decompose_seed</code> function, and a one-line entry in <code>_DECOMPOSITION_MAP</code>. No existing code is modified.</p>

        <h2>Key Takeaways</h2>

        <ul>
          <li><strong>Natural language is the natural interface for farm operators.</strong> Removing the translation step between human intent and robot action makes precision agriculture more accessible and more responsive to time-sensitive conditions.</li>
          <li><strong>Intent parsing and entity extraction are separable concerns.</strong> The intent answers "what"; the entities answer "where, when, how." Keeping them modular makes each component independently testable and extensible.</li>
          <li><strong>Task decomposition encodes domain expertise.</strong> The spray pipeline (weather check, configure, navigate, spray, return) reflects real agricultural standard operating procedures. The system's value comes from embedding this domain knowledge into structured, dependency-aware action sequences.</li>
          <li><strong>Confidence scores propagate uncertainty.</strong> When the parser is unsure, that uncertainty follows the plan all the way to the user, enabling informed human oversight rather than blind trust.</li>
        </ul>

        <h2>PhD Alignment</h2>

        <p>This work directly addresses a core objective in my target PhD position: developing <em>"algorithms for generating robot control processes given natural language utterances."</em> CropCommand demonstrates a complete pipeline from unstructured text to structured, dependency-ordered robot task plans. The next post will explore how constraint reasoning transforms a naive plan into one that respects the physical realities of weather, terrain, and robot capabilities.</p>

      </div>
      <div class="post-nav">
        <a href="../../blogs.html">&larr; Back to Blog</a>
        <a href="part2-constraints.html">Constraint Reasoning and Simulation &rarr;</a>
      </div>
    </article>
  </main>
  <footer class="footer">
    <div class="container">
      <p>&copy; 2026 Munyaradzi Comfort Zhou. Built with intention.</p>
    </div>
  </footer>
  <script src="../../js/main.js"></script>
</body>
</html>
